<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2fe5915a65e44700aab8d6718ec0d513</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MlcLm72gq8Xv" data-outputId="beee4ed4-5eb2-4b4c-b149-8091e8f3085c">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U datasets</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)
Collecting datasets
  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)
Collecting pyarrow&gt;=21.0.0 (from datasets)
  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
Requirement already satisfied: dill&lt;0.4.1,&gt;=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)
Requirement already satisfied: requests&gt;=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)
Requirement already satisfied: httpx&lt;1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)
Requirement already satisfied: tqdm&gt;=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)
Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)
Requirement already satisfied: multiprocess&lt;0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec&lt;=2025.10.0,&gt;=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (2025.3.0)
Requirement already satisfied: huggingface-hub&lt;2.0,&gt;=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (3.13.2)
Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx&lt;1.0.0-&gt;datasets) (4.12.0)
Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx&lt;1.0.0-&gt;datasets) (2025.11.12)
Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx&lt;1.0.0-&gt;datasets) (1.0.9)
Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx&lt;1.0.0-&gt;datasets) (3.11)
Requirement already satisfied: h11&gt;=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*-&gt;httpx&lt;1.0.0-&gt;datasets) (0.16.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&lt;2.0,&gt;=0.25.0-&gt;datasets) (4.15.0)
Requirement already satisfied: hf-xet&lt;2.0.0,&gt;=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&lt;2.0,&gt;=0.25.0-&gt;datasets) (1.2.0)
Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.12/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (3.4.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (2.5.0)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas-&gt;datasets) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas-&gt;datasets) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas-&gt;datasets) (2025.3)
Requirement already satisfied: aiohappyeyeballs&gt;=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (2.6.1)
Requirement already satisfied: aiosignal&gt;=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (1.4.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (25.4.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (1.8.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (6.7.0)
Requirement already satisfied: propcache&gt;=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (0.4.1)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;=2025.10.0,&gt;=2023.1.0-&gt;datasets) (1.22.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.17.0)
Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 512.3/512.3 kB 7.9 MB/s eta 0:00:00
anylinux_2_28_x86_64.whl (47.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.7/47.7 MB 11.0 MB/s eta 0:00:00
pting uninstall: pyarrow
    Found existing installation: pyarrow 18.1.0
    Uninstalling pyarrow-18.1.0:
      Successfully uninstalled pyarrow-18.1.0
  Attempting uninstall: datasets
    Found existing installation: datasets 4.0.0
    Uninstalling datasets-4.0.0:
      Successfully uninstalled datasets-4.0.0
Successfully installed datasets-4.4.2 pyarrow-22.0.0
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:576,&quot;referenced_widgets&quot;:[&quot;8282d8c1b6c24272a22255373eb38df1&quot;,&quot;52259fb54c014b7a82dfcc3895cf9dbc&quot;,&quot;cab44dae7da54a15899d08dfd99d9c96&quot;,&quot;670d67a85dd2473ab98d817238615a3c&quot;,&quot;3dc921e6a23e49a396581e3407e1b213&quot;,&quot;3425e3e965894a779509e26fb266619a&quot;,&quot;224aef01fdb14a869404467b8a7c4421&quot;,&quot;9c66972906574d1b98e4d927845843c4&quot;,&quot;f19a9ce04e414c2fbdb833916b30498d&quot;,&quot;75ea075ec11b4f24b03782aadbff9852&quot;,&quot;04ed34259b544c74b55412c426b001d0&quot;,&quot;fd22bed3007f4d279b622872e7e426ec&quot;,&quot;482fcce437fc49cd8604f544ce88ffbc&quot;,&quot;a87e289e899d497fac2974a97dbf56cf&quot;,&quot;0208627c85bb4b3f84d0d59a39bbbe86&quot;,&quot;01057fd523ba4b75891671837cf2823d&quot;,&quot;135bb1a99d1a4f3182b60f7ead5edeb1&quot;,&quot;ff3d75e764684288bc73973692323258&quot;,&quot;b8c05c18eb794197b6042c7e0859d5e1&quot;,&quot;091e0c0833cf4269b177cbad5cd5a372&quot;,&quot;fc0b419e97a44484ad8a137fde32300f&quot;,&quot;5b67f2079edd4e9880591cab15c1360f&quot;,&quot;eb936d647bf24d33b4af03e2072bde6f&quot;,&quot;48f714b8574d46039ced1925da863762&quot;,&quot;7de91c1897f0446490f13566227af5a9&quot;,&quot;23f79741fee54542b3b634e9e9ee331f&quot;,&quot;11e87dc56887436e91ab0a994818b5ed&quot;,&quot;b8c4be5c12514b52afd53516835ac458&quot;,&quot;03be48386b904ed29e992dae70a7066c&quot;,&quot;2c6dd29516144b509919f50c1535e7ca&quot;,&quot;2e65e3958eb64107a00117a87d10b41f&quot;,&quot;d3a62b04dfa34f6b82feb19f1853a45a&quot;,&quot;04ee52d23c3a4df5a5e03fe38dc7edd0&quot;,&quot;48f18e44aa6e4b4db7984bacfec2a05b&quot;,&quot;506123b947c74aa499db47d2d948a035&quot;,&quot;1e0fa2e0d6154016934d6902fe49cfec&quot;,&quot;69541af85f654f9a9f88a06df48d3024&quot;,&quot;58f492405e2d497ead14ca747ce2d557&quot;,&quot;4269679ae0884b0089185458d1415f5c&quot;,&quot;1fba7df6a99b4895bd9db8231fe7337a&quot;,&quot;f7c4d23df63d48fabb85712cd2b5c9e7&quot;,&quot;2c939e69b8d34c80b29a176a0987a5c3&quot;,&quot;b4353782fe2c40fda3745cbc26b29b96&quot;,&quot;5d72133f22fd4edebf63aab53aa9eb36&quot;,&quot;31e399922b2647e6ab160378c3ff5ad3&quot;,&quot;1deca4b9b7d44dd0b02090c4ac0dfd70&quot;,&quot;a0dcf7f89b95406abf2a95c564aa63c2&quot;,&quot;c59457d1ba6d426a8d996118a5ed343e&quot;,&quot;9c8004f8a408468b80845847c93f7d8b&quot;,&quot;6f18659602d545cc8991d9e0f8d98448&quot;,&quot;c2108e896a534d32b0867b86331ccf01&quot;,&quot;ec95db9d7bbb408a9a671202b59b2de7&quot;,&quot;94f56a0f85d74aa1889fb1bae9ad570c&quot;,&quot;136032961c164b019701971a93829637&quot;,&quot;16706ed0f7fc4661acfdf49171e143d5&quot;,&quot;58f329e0c36344ab9afe9ec71356d0f4&quot;,&quot;d7e595722af248578a7e560b33cc2332&quot;,&quot;f81580cc242f4a22ad0802d0d473b423&quot;,&quot;4dbc0045379d45348569bed074d9e048&quot;,&quot;3bc3904c437945f88ae076c1d5b02f95&quot;,&quot;fe218d1744eb4df88ac2d9165693096d&quot;,&quot;b7ec1cc0194c4e7eb372328de7e92feb&quot;,&quot;dd8492e2e6cc4e259249800056ceb73a&quot;,&quot;fd2e3b6eb757464a8259b651b8241ffc&quot;,&quot;24755552c34243da953ca0bb545fffdb&quot;,&quot;df8f18080e384443a5888f1097b4bcea&quot;]}"
id="uCBzkjH9rgXv" data-outputId="bc82adb4-bbc0-4c2b-8db4-9a1d5fd80fba">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> load_dataset(</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;allenai/qasper&quot;</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    revision<span class="op">=</span><span class="st">&quot;refs/convert/parquet&quot;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ds)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8282d8c1b6c24272a22255373eb38df1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb6"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fd22bed3007f4d279b622872e7e426ec&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb7"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;eb936d647bf24d33b4af03e2072bde6f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb8"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;48f18e44aa6e4b4db7984bacfec2a05b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb9"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;31e399922b2647e6ab160378c3ff5ad3&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb10"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;58f329e0c36344ab9afe9ec71356d0f4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>DatasetDict({
    train: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;abstract&#39;, &#39;full_text&#39;, &#39;qas&#39;, &#39;figures_and_tables&#39;],
        num_rows: 888
    })
    validation: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;abstract&#39;, &#39;full_text&#39;, &#39;qas&#39;, &#39;figures_and_tables&#39;],
        num_rows: 281
    })
    test: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;abstract&#39;, &#39;full_text&#39;, &#39;qas&#39;, &#39;figures_and_tables&#39;],
        num_rows: 416
    })
})
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="7NmUUsiYtDiK" data-outputId="56db85cc-e39a-4b5e-ff9e-643de6c3d99b">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> ds[<span class="st">&quot;train&quot;</span>]</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(train_ds))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>train_ds[<span class="dv">0</span>]</span></code></pre></div>
<div class="output stream stdout">
<pre><code>888
</code></pre>
</div>
<div class="output execute_result" data-execution_count="3">
<pre><code>{&#39;id&#39;: &#39;1909.00694&#39;,
 &#39;title&#39;: &#39;Minimally Supervised Learning of Affective Events Using Discourse Relations&#39;,
 &#39;abstract&#39;: &#39;Recognizing affective events that trigger positive or negative sentiment has a wide range of natural language processing applications but remains a challenging problem mainly because the polarity of an event is not necessarily predictable from its constituent words. In this paper, we propose to propagate affective polarity using discourse relations. Our method is simple and only requires a very small seed lexicon and a large raw corpus. Our experiments using Japanese data show that our method learns affective events effectively without manually labeled data. It also improves supervised learning results when labeled data are small.&#39;,
 &#39;full_text&#39;: {&#39;section_name&#39;: [&#39;Introduction&#39;,
   &#39;Related Work&#39;,
   &#39;Proposed Method&#39;,
   &#39;Proposed Method ::: Polarity Function&#39;,
   &#39;Proposed Method ::: Discourse Relation-Based Event Pairs&#39;,
   &#39;Proposed Method ::: Discourse Relation-Based Event Pairs ::: AL (Automatically Labeled Pairs)&#39;,
   &#39;Proposed Method ::: Discourse Relation-Based Event Pairs ::: CA (Cause Pairs)&#39;,
   &#39;Proposed Method ::: Discourse Relation-Based Event Pairs ::: CO (Concession Pairs)&#39;,
   &#39;Proposed Method ::: Loss Functions&#39;,
   &#39;Experiments&#39;,
   &#39;Experiments ::: Dataset&#39;,
   &#39;Experiments ::: Dataset ::: AL, CA, and CO&#39;,
   &#39;Experiments ::: Dataset ::: ACP (ACP Corpus)&#39;,
   &#39;Experiments ::: Model Configurations&#39;,
   &#39;Experiments ::: Results and Discussion&#39;,
   &#39;Conclusion&#39;,
   &#39;Acknowledgments&#39;,
   &#39;Appendices ::: Seed Lexicon ::: Positive Words&#39;,
   &#39;Appendices ::: Seed Lexicon ::: Negative Words&#39;,
   &#39;Appendices ::: Settings of Encoder ::: BiGRU&#39;,
   &#39;Appendices ::: Settings of Encoder ::: BERT&#39;],
  &#39;paragraphs&#39;: [[&quot;Affective events BIBREF0 are events that typically affect people in positive or negative ways. For example, getting money and playing sports are usually positive to the experiencers; catching cold and losing one&#39;s wallet are negative. Understanding affective events is important to various natural language processing (NLP) applications such as dialogue systems BIBREF1, question-answering systems BIBREF2, and humor recognition BIBREF3. In this paper, we work on recognizing the polarity of an affective event that is represented by a score ranging from $-1$ (negative) to 1 (positive).&quot;,
    &#39;Learning affective events is challenging because, as the examples above suggest, the polarity of an event is not necessarily predictable from its constituent words. Combined with the unbounded combinatorial nature of language, the non-compositionality of affective polarity entails the need for large amounts of world knowledge, which can hardly be learned from small annotated data.&#39;,
    &quot;In this paper, we propose a simple and effective method for learning affective events that only requires a very small seed lexicon and a large raw corpus. As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;,
    &#39;We trained the models using a Japanese web corpus. Given the minimum amount of supervision, they performed well. In addition, the combination of annotated and unannotated data yielded a gain over a purely supervised baseline when labeled data were small.&#39;],
   [&#39;Learning affective events is closely related to sentiment analysis. Whereas sentiment analysis usually focuses on the polarity of what are described (e.g., movies), we work on how people are typically affected by events. In sentiment analysis, much attention has been paid to compositionality. Word-level polarity BIBREF5, BIBREF6, BIBREF7 and the roles of negation and intensification BIBREF8, BIBREF6, BIBREF9 are among the most important topics. In contrast, we are more interested in recognizing the sentiment polarity of an event that pertains to commonsense knowledge (e.g., getting money and catching cold).&#39;,
    &#39;Label propagation from seed instances is a common approach to inducing sentiment polarities. While BIBREF5 and BIBREF10 worked on word- and phrase-level polarities, BIBREF0 dealt with event-level polarities. BIBREF5 and BIBREF10 linked instances using co-occurrence information and/or phrase-level coordinations (e.g., “$A$ and $B$” and “$A$ but $B$”). We shift our scope to event pairs that are more complex than phrase pairs, and consequently exploit discourse connectives as event-level counterparts of phrase-level conjunctions.&#39;,
    &#39;BIBREF0 constructed a network of events using word embedding-derived similarities. Compared with this method, our discourse relation-based linking of events is much simpler and more intuitive.&#39;,
    &#39;Some previous studies made use of document structure to understand the sentiment. BIBREF11 proposed a sentiment-specific pre-training strategy using unlabeled dialog data (tweet-reply pairs). BIBREF12 proposed a method of building a polarity-tagged corpus (ACP Corpus). They automatically gathered sentences that had positive or negative opinions utilizing HTML layout structures in addition to linguistic patterns. Our method depends only on raw texts and thus has wider applicability.&#39;,
    &#39;&#39;],
   [&#39;&#39;],
   [&#39;&#39;,
    &#39;Our goal is to learn the polarity function $p(x)$, which predicts the sentiment polarity score of an event $x$. We approximate $p(x)$ by a neural network with the following form:&#39;,
    &#39;${\\rm Encoder}$ outputs a vector representation of the event $x$. ${\\rm Linear}$ is a fully-connected layer and transforms the representation into a scalar. ${\\rm tanh}$ is the hyperbolic tangent and transforms the scalar into a score ranging from $-1$ to 1. In Section SECREF21, we consider two specific implementations of ${\\rm Encoder}$.&#39;,
    &#39;&#39;],
   [&#39;Our method requires a very small seed lexicon and a large raw corpus. We assume that we can automatically extract discourse-tagged event pairs, $(x_{i1}, x_{i2})$ ($i=1, \\cdots $) from the raw corpus. We refer to $x_{i1}$ and $x_{i2}$ as former and latter events, respectively. As shown in Figure FIGREF1, we limit our scope to two discourse relations: Cause and Concession.&#39;,
    &#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.&#39;,
    &#39;&#39;],
   [&quot;The seed lexicon matches (1) the latter event but (2) not the former event, and (3) their discourse relation type is Cause or Concession. If the discourse relation type is Cause, the former event is given the same score as the latter. Likewise, if the discourse relation type is Concession, the former event is given the opposite of the latter&#39;s score. They are used as reference scores during training.&quot;,
    &#39;&#39;],
   [&#39;The seed lexicon matches neither the former nor the latter event, and their discourse relation type is Cause. We assume the two events have the same polarities.&#39;,
    &#39;&#39;],
   [&#39;The seed lexicon matches neither the former nor the latter event, and their discourse relation type is Concession. We assume the two events have the reversed polarities.&#39;,
    &#39;&#39;],
   [&#39;Using AL, CA, and CO data, we optimize the parameters of the polarity function $p(x)$. We define a loss function for each of the three types of event pairs and sum up the multiple loss functions.&#39;,
    &#39;We use mean squared error to construct loss functions. For the AL data, the loss function is defined as:&#39;,
    &#39;where $x_{i1}$ and $x_{i2}$ are the $i$-th pair of the AL data. $r_{i1}$ and $r_{i2}$ are the automatically-assigned scores of $x_{i1}$ and $x_{i2}$, respectively. $N_{\\rm AL}$ is the total number of AL pairs, and $\\lambda _{\\rm AL}$ is a hyperparameter.&#39;,
    &#39;For the CA data, the loss function is defined as:&#39;,
    &#39;$y_{i1}$ and $y_{i2}$ are the $i$-th pair of the CA pairs. $N_{\\rm CA}$ is the total number of CA pairs. $\\lambda _{\\rm CA}$ and $\\mu $ are hyperparameters. The first term makes the scores of the two events closer while the second term prevents the scores from shrinking to zero.&#39;,
    &#39;The loss function for the CO data is defined analogously:&#39;,
    &#39;The difference is that the first term makes the scores of the two events distant from each other.&#39;,
    &#39;&#39;],
   [&#39;&#39;],
   [&#39;&#39;],
   [&#39;As a raw corpus, we used a Japanese web corpus that was compiled through the procedures proposed by BIBREF13. To extract event pairs tagged with discourse relations, we used the Japanese dependency parser KNP and in-house postprocessing scripts BIBREF14. KNP used hand-written rules to segment each sentence into what we conventionally called clauses (mostly consecutive text chunks), each of which contained one main predicate. KNP also identified the discourse relations of event pairs if explicit discourse connectives BIBREF4 such as “ので” (because) and “のに” (in spite of) were present. We treated Cause/Reason (原因・理由) and Condition (条件) in the original tagset BIBREF15 as Cause and Concession (逆接) as Concession, respectively. Here is an example of event pair extraction.&#39;,
    &#39;. 重大な失敗を犯したので、仕事をクビになった。&#39;,
    &#39;Because [I] made a serious mistake, [I] got fired.&#39;,
    &#39;From this sentence, we extracted the event pair of “重大な失敗を犯す” ([I] make a serious mistake) and “仕事をクビになる” ([I] get fired), and tagged it with Cause.&#39;,
    &#39;We constructed our seed lexicon consisting of 15 positive words and 15 negative words, as shown in Section SECREF27. From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO. We randomly selected subsets of AL event pairs such that positive and negative latter events were equal in size. We also sampled event pairs for each of CA and CO such that it was five times larger than AL. The results are shown in Table TABREF16.&#39;],
   [&#39;We used the latest version of the ACP Corpus BIBREF12 for evaluation. It was used for (semi-)supervised training as well. Extracted from Japanese websites using HTML layouts and linguistic patterns, the dataset covered various genres. For example, the following two sentences were labeled positive and negative, respectively:&#39;,
    &#39;. 作業が楽だ。&#39;,
    &#39;The work is easy.&#39;,
    &#39;. 駐車場がない。&#39;,
    &#39;There is no parking lot.&#39;,
    &#39;Although the ACP corpus was originally constructed in the context of sentiment analysis, we found that it could roughly be regarded as a collection of affective events. We parsed each sentence and extracted the last clause in it. The train/dev/test split of the data is shown in Table TABREF19.&#39;,
    &#39;The objective function for supervised training is:&#39;,
    &#39;&#39;,
    &#39;where $v_i$ is the $i$-th event, $R_i$ is the reference score of $v_i$, and $N_{\\rm ACP}$ is the number of the events of the ACP Corpus.&#39;,
    &#39;To optimize the hyperparameters, we used the dev set of the ACP Corpus. For the evaluation, we used the test set of the ACP Corpus. The model output was classified as positive if $p(x) &gt; 0$ and negative if $p(x) \\le 0$.&#39;,
    &#39;&#39;],
   [&#39;As for ${\\rm Encoder}$, we compared two types of neural networks: BiGRU and BERT. GRU BIBREF16 is a recurrent neural network sequence encoder. BiGRU reads an input sequence forward and backward and the output is the concatenation of the final forward and backward hidden states.&#39;,
    &#39;BERT BIBREF17 is a pre-trained multi-layer bidirectional Transformer BIBREF18 encoder. Its output is the final hidden state corresponding to the special classification tag ([CLS]). For the details of ${\\rm Encoder}$, see Sections SECREF30.&#39;,
    &#39;We trained the model with the following four combinations of the datasets: AL, AL+CA+CO (two proposed models), ACP (supervised), and ACP+AL+CA+CO (semi-supervised). The corresponding objective functions were: $\\mathcal {L}_{\\rm AL}$, $\\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$, $\\mathcal {L}_{\\rm ACP}$, and $\\mathcal {L}_{\\rm ACP} + \\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$.&#39;,
    &#39;&#39;],
   [&#39;&#39;,
    &quot;Table TABREF23 shows accuracy. As the Random baseline suggests, positive and negative labels were distributed evenly. The Random+Seed baseline made use of the seed lexicon and output the corresponding label (or the reverse of it for negation) if the event&#39;s predicate is in the seed lexicon. We can see that the seed lexicon itself had practically no impact on prediction.&quot;,
    &#39;The models in the top block performed considerably better than the random baselines. The performance gaps with their (semi-)supervised counterparts, shown in the middle block, were less than 7%. This demonstrates the effectiveness of discourse relation-based label propagation.&#39;,
    &#39;Comparing the model variants, we obtained the highest score with the BiGRU encoder trained with the AL+CA+CO dataset. BERT was competitive but its performance went down if CA and CO were used in addition to AL. We conjecture that BERT was more sensitive to noises found more frequently in CA and CO.&#39;,
    &#39;Contrary to our expectations, supervised models (ACP) outperformed semi-supervised models (ACP+AL+CA+CO). This suggests that the training set of 0.6 million events is sufficiently large for training the models. For comparison, we trained the models with a subset (6,000 events) of the ACP dataset. As the results shown in Table TABREF24 demonstrate, our method is effective when labeled data are small.&#39;,
    &#39;The result of hyperparameter optimization for the BiGRU encoder was as follows:&#39;,
    &#39;As the CA and CO pairs were equal in size (Table TABREF16), $\\lambda _{\\rm CA}$ and $\\lambda _{\\rm CO}$ were comparable values. $\\lambda _{\\rm CA}$ was about one-third of $\\lambda _{\\rm CO}$, and this indicated that the CA pairs were noisier than the CO pairs. A major type of CA pairs that violates our assumption was in the form of “$\\textit {problem}_{\\text{negative}}$ causes $\\textit {solution}_{\\text{positive}}$”:&#39;,
    &#39;. (悪いところがある, よくなるように努力する)&#39;,
    &#39;(there is a bad point, [I] try to improve [it])&#39;,
    &#39;The polarities of the two events were reversed in spite of the Cause relation, and this lowered the value of $\\lambda _{\\rm CA}$.&#39;,
    &#39;Some examples of model outputs are shown in Table TABREF26. The first two examples suggest that our model successfully learned negation without explicit supervision. Similarly, the next two examples differ only in voice but the model correctly recognized that they had opposite polarities. The last two examples share the predicate “落とす&quot; (drop) and only the objects are different. The second event “肩を落とす&quot; (lit. drop one\&#39;s shoulders) is an idiom that expresses a disappointed feeling. The examples demonstrate that our model correctly learned non-compositional expressions.&#39;,
    &#39;&#39;],
   [&#39;In this paper, we proposed to use discourse relations to effectively propagate polarities of affective events from seeds. Experiments show that, even with a minimal amount of supervision, the proposed method performed well.&#39;,
    &#39;Although event pairs linked by discourse analysis are shown to be useful, they nevertheless contain noises. Adding linguistically-motivated filtering rules would help improve the performance.&#39;],
   [&#39;We thank Nobuhiro Kaji for providing the ACP Corpus and Hirokazu Kiyomaru and Yudai Kishimoto for their help in extracting event pairs. This work was partially supported by Yahoo! Japan Corporation.&#39;],
   [&#39;喜ぶ (rejoice), 嬉しい (be glad), 楽しい (be pleasant), 幸せ (be happy), 感動 (be impressed), 興奮 (be excited), 懐かしい (feel nostalgic), 好き (like), 尊敬 (respect), 安心 (be relieved), 感心 (admire), 落ち着く (be calm), 満足 (be satisfied), 癒される (be healed), and スッキリ (be refreshed).&#39;],
   [&#39;怒る (get angry), 悲しい (be sad), 寂しい (be lonely), 怖い (be scared), 不安 (feel anxious), 恥ずかしい (be embarrassed), 嫌 (hate), 落ち込む (feel down), 退屈 (be bored), 絶望 (feel hopeless), 辛い (have a hard time), 困る (have trouble), 憂鬱 (be depressed), 心配 (be worried), and 情けない (be sorry).&#39;],
   [&#39;The dimension of the embedding layer was 256. The embedding layer was initialized with the word embeddings pretrained using the Web corpus. The input sentences were segmented into words by the morphological analyzer Juman++. The vocabulary size was 100,000. The number of hidden layers was 2. The dimension of hidden units was 256. The optimizer was Momentum SGD BIBREF21. The mini-batch size was 1024. We ran 100 epochs and selected the snapshot that achieved the highest score for the dev set.&#39;],
   [&#39;We used a Japanese BERT model pretrained with Japanese Wikipedia. The input sentences were segmented into words by Juman++, and words were broken into subwords by applying BPE BIBREF20. The vocabulary size was 32,000. The maximum length of an input sequence was 128. The number of hidden layers was 12. The dimension of hidden units was 768. The number of self-attention heads was 12. The optimizer was Adam BIBREF19. The mini-batch size was 32. We ran 1 epoch.&#39;]]},
 &#39;qas&#39;: {&#39;question&#39;: [&#39;What is the seed lexicon?&#39;,
   &#39;What are the results?&#39;,
   &#39;How are relations used to propagate polarity?&#39;,
   &#39;How big is the Japanese data?&#39;,
   &#39;What are labels available in dataset for supervision?&#39;,
   &#39;How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?&#39;,
   &#39;How does their model learn using mostly raw data?&#39;,
   &#39;How big is seed lexicon used for training?&#39;,
   &#39;How large is raw corpus used for training?&#39;],
  &#39;question_id&#39;: [&#39;753990d0b621d390ed58f20c4d9e4f065f0dc672&#39;,
   &#39;9d578ddccc27dd849244d632dd0f6bf27348ad81&#39;,
   &#39;02e4bf719b1a504e385c35c6186742e720bcb281&#39;,
   &#39;44c4bd6decc86f1091b5fc0728873d9324cdde4e&#39;,
   &#39;86abeff85f3db79cf87a8c993e5e5aa61226dc98&#39;,
   &#39;c029deb7f99756d2669abad0a349d917428e9c12&#39;,
   &#39;39f8db10d949c6b477fa4b51e7c184016505884f&#39;,
   &#39;d0bc782961567dc1dd7e074b621a6d6be44bb5b4&#39;,
   &#39;a592498ba2fac994cd6fad7372836f0adb37e22a&#39;],
  &#39;nlp_background&#39;: [&#39;two&#39;,
   &#39;two&#39;,
   &#39;two&#39;,
   &#39;two&#39;,
   &#39;zero&#39;,
   &#39;zero&#39;,
   &#39;zero&#39;,
   &#39;zero&#39;,
   &#39;zero&#39;],
  &#39;topic_background&#39;: [&#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;,
   &#39;unfamiliar&#39;],
  &#39;paper_read&#39;: [&#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;],
  &#39;search_query&#39;: [&#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;],
  &#39;question_writer&#39;: [&#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
   &#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
   &#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
   &#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
   &#39;258ee4069f740c400c0049a2580945a1cc7f044c&#39;,
   &#39;258ee4069f740c400c0049a2580945a1cc7f044c&#39;,
   &#39;258ee4069f740c400c0049a2580945a1cc7f044c&#39;,
   &#39;258ee4069f740c400c0049a2580945a1cc7f044c&#39;,
   &#39;258ee4069f740c400c0049a2580945a1cc7f044c&#39;],
  &#39;answers&#39;: [{&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;a vocabulary of positive and negative predicates that helps determine the polarity score of an event&#39;,
      &#39;evidence&#39;: [&#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event.&#39;,
       &#39;It is a &#39;]},
     {&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [&#39;seed lexicon consists of positive and negative predicates&#39;],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;&#39;,
      &#39;evidence&#39;: [&#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event.&#39;]}],
    &#39;annotation_id&#39;: [&#39;31e85022a847f37c15fd0415f3c450c74c8e4755&#39;,
     &#39;95da0a6e1b08db74a405c6a71067c9b272a50ff5&#39;],
    &#39;worker_id&#39;: [&#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
     &#39;2cfd959e433f290bb50b55722370f0d22fe090b7&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.&#39;,
      &#39;evidence&#39;: [&#39;FLOAT SELECTED: Table 3: Performance of various models on the ACP test set.&#39;,
       &#39;FLOAT SELECTED: Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.&#39;,
       &#39;As for ${\\rm Encoder}$, we compared two types of neural networks: BiGRU and BERT. GRU BIBREF16 is a recurrent neural network sequence encoder. BiGRU reads an input sequence forward and backward and the output is the concatenation of the final forward and backward hidden states.&#39;,
       &#39;We trained the model with the following four combinations of the datasets: AL, AL+CA+CO (two proposed models), ACP (supervised), and ACP+AL+CA+CO (semi-supervised). The corresponding objective functions were: $\\mathcal {L}_{\\rm AL}$, $\\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$, $\\mathcal {L}_{\\rm ACP}$, and $\\mathcal {L}_{\\rm ACP} + \\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;FLOAT SELECTED: Table 3: Performance of various models on the ACP test set.&#39;,
       &#39;FLOAT SELECTED: Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.&#39;,
       &#39;As for ${\\rm Encoder}$, we compared two types of neural networks: BiGRU and BERT. &#39;,
       &#39;We trained the model with the following four combinations of the datasets: AL, AL+CA+CO (two proposed models), ACP (supervised), and ACP+AL+CA+CO (semi-supervised). The corresponding objective functions were: $\\mathcal {L}_{\\rm AL}$, $\\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$, $\\mathcal {L}_{\\rm ACP}$, and $\\mathcal {L}_{\\rm ACP} + \\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$.&#39;]}],
    &#39;annotation_id&#39;: [&#39;1e5e867244ea656c4b7632628086209cf9bae5fa&#39;],
    &#39;worker_id&#39;: [&#39;2cfd959e433f290bb50b55722370f0d22fe090b7&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event &#39;,
      &#39;evidence&#39;: [&quot;In this paper, we propose a simple and effective method for learning affective events that only requires a very small seed lexicon and a large raw corpus. As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;],
      &#39;highlighted_evidence&#39;: [&quot;As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;]},
     {&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity&#39;,
      &#39;evidence&#39;: [&quot;In this paper, we propose a simple and effective method for learning affective events that only requires a very small seed lexicon and a large raw corpus. As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;,
       &#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.&#39;],
      &#39;highlighted_evidence&#39;: [&quot;As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;,
       &#39;The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation.&#39;]}],
    &#39;annotation_id&#39;: [&#39;49a78a07d2eed545556a835ccf2eb40e5eee9801&#39;,
     &#39;acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1&#39;],
    &#39;worker_id&#39;: [&#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;,
     &#39;2cfd959e433f290bb50b55722370f0d22fe090b7&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus&#39;,
      &#39;evidence&#39;: [&#39;As a raw corpus, we used a Japanese web corpus that was compiled through the procedures proposed by BIBREF13. To extract event pairs tagged with discourse relations, we used the Japanese dependency parser KNP and in-house postprocessing scripts BIBREF14. KNP used hand-written rules to segment each sentence into what we conventionally called clauses (mostly consecutive text chunks), each of which contained one main predicate. KNP also identified the discourse relations of event pairs if explicit discourse connectives BIBREF4 such as “ので” (because) and “のに” (in spite of) were present. We treated Cause/Reason (原因・理由) and Condition (条件) in the original tagset BIBREF15 as Cause and Concession (逆接) as Concession, respectively. Here is an example of event pair extraction.&#39;,
       &#39;We constructed our seed lexicon consisting of 15 positive words and 15 negative words, as shown in Section SECREF27. From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO. We randomly selected subsets of AL event pairs such that positive and negative latter events were equal in size. We also sampled event pairs for each of CA and CO such that it was five times larger than AL. The results are shown in Table TABREF16.&#39;,
       &#39;FLOAT SELECTED: Table 1: Statistics of the AL, CA, and CO datasets.&#39;,
       &#39;We used the latest version of the ACP Corpus BIBREF12 for evaluation. It was used for (semi-)supervised training as well. Extracted from Japanese websites using HTML layouts and linguistic patterns, the dataset covered various genres. For example, the following two sentences were labeled positive and negative, respectively:&#39;,
       &#39;Although the ACP corpus was originally constructed in the context of sentiment analysis, we found that it could roughly be regarded as a collection of affective events. We parsed each sentence and extracted the last clause in it. The train/dev/test split of the data is shown in Table TABREF19.&#39;,
       &#39;FLOAT SELECTED: Table 2: Details of the ACP dataset.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;As a raw corpus, we used a Japanese web corpus that was compiled through the procedures proposed by BIBREF13. &#39;,
       &#39;From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO. We randomly selected subsets of AL event pairs such that positive and negative latter events were equal in size. We also sampled event pairs for each of CA and CO such that it was five times larger than AL. The results are shown in Table TABREF16.&#39;,
       &#39;FLOAT SELECTED: Table 1: Statistics of the AL, CA, and CO datasets.&#39;,
       &#39;We used the latest version of the ACP Corpus BIBREF12 for evaluation. It was used for (semi-)supervised training as well.&#39;,
       &#39;Although the ACP corpus was originally constructed in the context of sentiment analysis, we found that it could roughly be regarded as a collection of affective events. We parsed each sentence and extracted the last clause in it. The train/dev/test split of the data is shown in Table TABREF19.&#39;,
       &#39;FLOAT SELECTED: Table 2: Details of the ACP dataset.&#39;]},
     {&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;The ACP corpus has around 700k events split into positive and negative polarity &#39;,
      &#39;evidence&#39;: [&#39;FLOAT SELECTED: Table 2: Details of the ACP dataset.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;FLOAT SELECTED: Table 2: Details of the ACP dataset.&#39;]}],
    &#39;annotation_id&#39;: [&#39;36926a4c9e14352c91111150aa4c6edcc5c0770f&#39;,
     &#39;75b6dd28ccab20a70087635d89c2b22d0e99095c&#39;],
    &#39;worker_id&#39;: [&#39;2cfd959e433f290bb50b55722370f0d22fe090b7&#39;,
     &#39;c1fbdd7a261021041f75fbe00a55b4c386ebbbb4&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [&#39;negative&#39;, &#39;positive&#39;],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;&#39;,
      &#39;evidence&#39;: [&quot;Affective events BIBREF0 are events that typically affect people in positive or negative ways. For example, getting money and playing sports are usually positive to the experiencers; catching cold and losing one&#39;s wallet are negative. Understanding affective events is important to various natural language processing (NLP) applications such as dialogue systems BIBREF1, question-answering systems BIBREF2, and humor recognition BIBREF3. In this paper, we work on recognizing the polarity of an affective event that is represented by a score ranging from $-1$ (negative) to 1 (positive).&quot;],
      &#39;highlighted_evidence&#39;: [&#39;In this paper, we work on recognizing the polarity of an affective event that is represented by a score ranging from $-1$ (negative) to 1 (positive).&#39;]}],
    &#39;annotation_id&#39;: [&#39;2d8c7df145c37aad905e48f64d8caa69e54434d4&#39;],
    &#39;worker_id&#39;: [&#39;c1018a31c3272ce74964a3280069f62f314a1a58&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;3%&#39;,
      &#39;evidence&#39;: [&#39;FLOAT SELECTED: Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;FLOAT SELECTED: Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.&#39;]}],
    &#39;annotation_id&#39;: [&#39;df4372b2e8d9bb2039a5582f192768953b01d904&#39;],
    &#39;worker_id&#39;: [&#39;c1018a31c3272ce74964a3280069f62f314a1a58&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity&#39;,
      &#39;evidence&#39;: [&quot;In this paper, we propose a simple and effective method for learning affective events that only requires a very small seed lexicon and a large raw corpus. As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive). Suppose that events $x_1$ are $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$). If the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The fact that $x_2$ is known to be negative indicates the negative polarity of $x_1$. Similarly, if $x_1$ and $x_2$ are in the discourse relation of Concession (i.e., $x_2$ in spite of $x_1$), the reverse of $x_2$&#39;s polarity can be propagated to $x_1$. Even if $x_2$&#39;s polarity is not known in advance, we can exploit the tendency of $x_1$ and $x_2$ to be of the same polarity (for Cause) or of the reverse polarity (for Concession) although the heuristic is not exempt from counterexamples. We transform this idea into objective functions and train neural network models that predict the polarity of a given event.&quot;],
      &#39;highlighted_evidence&#39;: [&quot;In this paper, we propose a simple and effective method for learning affective events that only requires a very small seed lexicon and a large raw corpus. As illustrated in Figure FIGREF1, our key idea is that we can exploit discourse relations BIBREF4 to efficiently propagate polarity from seed predicates that directly report one&#39;s emotions (e.g., “to be glad” is positive).&quot;]}],
    &#39;annotation_id&#39;: [&#39;5c5bbc8af91c16af89b4ddd57ee6834be018e4e7&#39;],
    &#39;worker_id&#39;: [&#39;c1018a31c3272ce74964a3280069f62f314a1a58&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;30 words&#39;,
      &#39;evidence&#39;: [&#39;We constructed our seed lexicon consisting of 15 positive words and 15 negative words, as shown in Section SECREF27. From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO. We randomly selected subsets of AL event pairs such that positive and negative latter events were equal in size. We also sampled event pairs for each of CA and CO such that it was five times larger than AL. The results are shown in Table TABREF16.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;We constructed our seed lexicon consisting of 15 positive words and 15 negative words, as shown in Section SECREF27. &#39;]}],
    &#39;annotation_id&#39;: [&#39;0206f2131f64a3e02498cedad1250971b78ffd0c&#39;],
    &#39;worker_id&#39;: [&#39;c1018a31c3272ce74964a3280069f62f314a1a58&#39;]},
   {&#39;answer&#39;: [{&#39;unanswerable&#39;: False,
      &#39;extractive_spans&#39;: [&#39;100 million sentences&#39;],
      &#39;yes_no&#39;: None,
      &#39;free_form_answer&#39;: &#39;&#39;,
      &#39;evidence&#39;: [&#39;As a raw corpus, we used a Japanese web corpus that was compiled through the procedures proposed by BIBREF13. To extract event pairs tagged with discourse relations, we used the Japanese dependency parser KNP and in-house postprocessing scripts BIBREF14. KNP used hand-written rules to segment each sentence into what we conventionally called clauses (mostly consecutive text chunks), each of which contained one main predicate. KNP also identified the discourse relations of event pairs if explicit discourse connectives BIBREF4 such as “ので” (because) and “のに” (in spite of) were present. We treated Cause/Reason (原因・理由) and Condition (条件) in the original tagset BIBREF15 as Cause and Concession (逆接) as Concession, respectively. Here is an example of event pair extraction.&#39;,
       &#39;We constructed our seed lexicon consisting of 15 positive words and 15 negative words, as shown in Section SECREF27. From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO. We randomly selected subsets of AL event pairs such that positive and negative latter events were equal in size. We also sampled event pairs for each of CA and CO such that it was five times larger than AL. The results are shown in Table TABREF16.&#39;],
      &#39;highlighted_evidence&#39;: [&#39;As a raw corpus, we used a Japanese web corpus that was compiled through the procedures proposed by BIBREF13. &#39;,
       &#39;From the corpus of about 100 million sentences, we obtained 1.4 millions event pairs for AL, 41 millions for CA, and 6 millions for CO.&#39;]}],
    &#39;annotation_id&#39;: [&#39;c36bad2758c4f9866d64c357c475d370595d937f&#39;],
    &#39;worker_id&#39;: [&#39;c1018a31c3272ce74964a3280069f62f314a1a58&#39;]}]},
 &#39;figures_and_tables&#39;: {&#39;caption&#39;: [&#39;Figure 1: An overview of our method. We focus on pairs of events, the former events and the latter events, which are connected with a discourse relation, CAUSE or CONCESSION. Dropped pronouns are indicated by brackets in English translations. We divide the event pairs into three types: AL, CA, and CO. In AL, the polarity of a latter event is automatically identified as either positive or negative, according to the seed lexicon (the positive word is colored red and the negative word blue). We propagate the latter event’s polarity to the former event. The same polarity as the latter event is used for the discourse relation CAUSE, and the reversed polarity for CONCESSION. In CA and CO, the latter event’s polarity is not known. Depending on the discourse relation, we encourage the two events’ polarities to be the same (CA) or reversed (CO). Details are given in Section 3.2.&#39;,
   &#39;Table 1: Statistics of the AL, CA, and CO datasets.&#39;,
   &#39;Table 2: Details of the ACP dataset.&#39;,
   &#39;Table 5: Examples of polarity scores predicted by the BiGRU model trained with AL+CA+CO.&#39;,
   &#39;Table 3: Performance of various models on the ACP test set.&#39;,
   &#39;Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.&#39;],
  &#39;file&#39;: [&#39;2-Figure1-1.png&#39;,
   &#39;4-Table1-1.png&#39;,
   &#39;4-Table2-1.png&#39;,
   &#39;5-Table5-1.png&#39;,
   &#39;5-Table3-1.png&#39;,
   &#39;5-Table4-1.png&#39;]}}</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pusghjbuxaEc" data-outputId="6b94ec5e-8b50-49f7-d040-abe8c0f414d5">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> train_ds[<span class="dv">0</span>]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>sample.keys()</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<pre><code>dict_keys([&#39;id&#39;, &#39;title&#39;, &#39;abstract&#39;, &#39;full_text&#39;, &#39;qas&#39;, &#39;figures_and_tables&#39;])</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:36}"
id="aQei0JOcHrwx" data-outputId="dc9f39c8-7177-4106-9d3b-4a020f1f6f3e">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>sample_qas <span class="op">=</span> train_ds[<span class="dv">0</span>][<span class="st">&quot;qas&quot;</span>][<span class="st">&quot;question&quot;</span>][<span class="dv">0</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>sample_qas</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<div class="sourceCode" id="cb18"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="H5BKLHG-0eLg" data-outputId="086c048d-59e5-4f13-9f9b-9eea8f70eacb">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>qas <span class="op">=</span> train_ds[<span class="dv">0</span>][<span class="st">&quot;qas&quot;</span>]</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(qas[<span class="st">&quot;question&quot;</span>])):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Question: </span><span class="sc">{</span>qas[<span class="st">&quot;question&quot;</span>][i]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Access the first free_form_answer for the current question</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(qas[<span class="st">&quot;answers&quot;</span>]) <span class="op">&gt;</span> i <span class="kw">and</span> <span class="bu">len</span>(qas[<span class="st">&quot;answers&quot;</span>][i][<span class="st">&quot;answer&quot;</span>]) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Answer: </span><span class="sc">{</span>qas[<span class="st">&quot;answers&quot;</span>][i][<span class="st">&quot;answer&quot;</span>][<span class="dv">0</span>][<span class="st">&quot;free_form_answer&quot;</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Answer: Not available or unanswerable.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Question: What is the seed lexicon?
Answer: a vocabulary of positive and negative predicates that helps determine the polarity score of an event
Question: What are the results?
Answer: Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. 
Using a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.
Question: How are relations used to propagate polarity?
Answer: based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event 
Question: How big is the Japanese data?
Answer: 7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus
Question: What are labels available in dataset for supervision?
Answer: 
Question: How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?
Answer: 3%
Question: How does their model learn using mostly raw data?
Answer: by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity
Question: How big is seed lexicon used for training?
Answer: 30 words
Question: How large is raw corpus used for training?
Answer: 
</code></pre>
</div>
</div>
<div class="cell markdown" id="3AX5YWty18_L">
<p>#Preprocessing</p>
</div>
<div class="cell code" id="CYL4lvH41YWn">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>processed_data <span class="op">=</span> []</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> train_ds:</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    paper_id <span class="op">=</span> item[<span class="st">&quot;id&quot;</span>]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    title <span class="op">=</span> item[<span class="st">&quot;title&quot;</span>]</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    abstract <span class="op">=</span> item[<span class="st">&quot;abstract&quot;</span>]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    context <span class="op">=</span> item[<span class="st">&quot;full_text&quot;</span>]</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    qas_data <span class="op">=</span> item[<span class="st">&quot;qas&quot;</span>]</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(qas_data[<span class="st">&quot;question&quot;</span>])):</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        question <span class="op">=</span> qas_data[<span class="st">&quot;question&quot;</span>][i]</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        answer <span class="op">=</span> <span class="st">&quot;&quot;</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if there&#39;s an answer entry for this question index</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(qas_data[<span class="st">&quot;answers&quot;</span>]) <span class="kw">and</span> <span class="bu">len</span>(qas_data[<span class="st">&quot;answers&quot;</span>][i][<span class="st">&quot;answer&quot;</span>]) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the free_form_answer from the first answer object</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            answer <span class="op">=</span> qas_data[<span class="st">&quot;answers&quot;</span>][i][<span class="st">&quot;answer&quot;</span>][<span class="dv">0</span>][<span class="st">&quot;free_form_answer&quot;</span>]</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Note: &#39;answer_type&#39; is not directly available at this level of the &#39;qas&#39; structure</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and would need to be inferred or extracted from the &#39;answer&#39; object if needed.</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        processed_data.append({</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;paper_id&quot;</span>: paper_id,</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;title&quot;</span>: title,</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;abstract&quot;</span>: abstract,</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;question&quot;</span>: question,</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;answer&quot;</span>: answer,</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;context&quot;</span>: context</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        })</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:293}"
id="Ti70p3sf125v" data-outputId="75991bd2-8ee4-4034-b9b1-789c7c60e3c8">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(processed_data)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">

  <div id="df-e96d17a2-64a0-4eca-9935-1bd0984008f0" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paper_id</th>
      <th>title</th>
      <th>abstract</th>
      <th>question</th>
      <th>answer</th>
      <th>context</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1909.00694</td>
      <td>Minimally Supervised Learning of Affective Eve...</td>
      <td>Recognizing affective events that trigger posi...</td>
      <td>What is the seed lexicon?</td>
      <td>a vocabulary of positive and negative predicat...</td>
      <td>{'section_name': ['Introduction', 'Related Wor...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1909.00694</td>
      <td>Minimally Supervised Learning of Affective Eve...</td>
      <td>Recognizing affective events that trigger posi...</td>
      <td>What are the results?</td>
      <td>Using all data to train: AL -- BiGRU achieved ...</td>
      <td>{'section_name': ['Introduction', 'Related Wor...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1909.00694</td>
      <td>Minimally Supervised Learning of Affective Eve...</td>
      <td>Recognizing affective events that trigger posi...</td>
      <td>How are relations used to propagate polarity?</td>
      <td>based on the relation between events, the sugg...</td>
      <td>{'section_name': ['Introduction', 'Related Wor...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1909.00694</td>
      <td>Minimally Supervised Learning of Affective Eve...</td>
      <td>Recognizing affective events that trigger posi...</td>
      <td>How big is the Japanese data?</td>
      <td>7000000 pairs of events were extracted from th...</td>
      <td>{'section_name': ['Introduction', 'Related Wor...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1909.00694</td>
      <td>Minimally Supervised Learning of Affective Eve...</td>
      <td>Recognizing affective events that trigger posi...</td>
      <td>What are labels available in dataset for super...</td>
      <td></td>
      <td>{'section_name': ['Introduction', 'Related Wor...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e96d17a2-64a0-4eca-9935-1bd0984008f0')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e96d17a2-64a0-4eca-9935-1bd0984008f0 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e96d17a2-64a0-4eca-9935-1bd0984008f0');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-504f731c-4ae4-430f-afc8-a655154011b2">
      <button class="colab-df-quickchart" onclick="quickchart('df-504f731c-4ae4-430f-afc8-a655154011b2')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-504f731c-4ae4-430f-afc8-a655154011b2 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>

</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:272}"
id="3PHacMSC2Slv" data-outputId="1599cf05-faa8-46e2-ffd3-0502f8c95b25">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>paper_id</th>
      <td>0</td>
    </tr>
    <tr>
      <th>title</th>
      <td>0</td>
    </tr>
    <tr>
      <th>abstract</th>
      <td>0</td>
    </tr>
    <tr>
      <th>question</th>
      <td>0</td>
    </tr>
    <tr>
      <th>answer</th>
      <td>0</td>
    </tr>
    <tr>
      <th>context</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
<div class="cell code" id="5HrcHhqE2V9t">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">&quot;answer&quot;</span>].<span class="bu">str</span>.<span class="bu">len</span>() <span class="op">&gt;</span> <span class="dv">0</span>]</span></code></pre></div>
</div>
<div class="cell code" id="p3aMSDCA2ZIa">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;question_length&quot;</span>] <span class="op">=</span> df[<span class="st">&quot;question&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(x.split()))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;answer_length&quot;</span>]   <span class="op">=</span> df[<span class="st">&quot;answer&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(x.split()))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;context_length&quot;</span>]  <span class="op">=</span> df[<span class="st">&quot;context&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(<span class="st">&#39; &#39;</span>.join([<span class="st">&#39; &#39;</span>.join(section) <span class="cf">for</span> section <span class="kw">in</span> x[<span class="st">&#39;paragraphs&#39;</span>]]).split()))</span></code></pre></div>
</div>
<div class="cell markdown" id="29UzlVUM2vg_">
<p>#DATA VISUALIZATION PART</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:459}"
id="VS36ySJ82yjw" data-outputId="cf4700c7-3eac-4d07-cffe-02abbc821062">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;answer&quot;</span>].unique()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_answer(x):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(x, <span class="bu">str</span>):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;unknown&quot;</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.lower()</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&quot;extractive&quot;</span> <span class="kw">in</span> x:</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;extractive&quot;</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&quot;abstractive&quot;</span> <span class="kw">in</span> x:</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;abstractive&quot;</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&quot;yes&quot;</span> <span class="kw">in</span> x:</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;yes/no&quot;</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&quot;unanswerable&quot;</span> <span class="kw">in</span> x:</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;unanswerable&quot;</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;unknown&quot;</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;answer_clean&quot;</span>] <span class="op">=</span> df[<span class="st">&quot;answer&quot;</span>].<span class="bu">apply</span>(clean_answer)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> df[<span class="st">&quot;answer_clean&quot;</span>].value_counts()</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>counts.plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Answer Type Distribution (Cleaned)&quot;</span>)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Answer Type&quot;</span>)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Count&quot;</span>)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/21b73f3cb8f8b06a674de11a7248495e7c459fb5.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="MqPHl6ep5qGj" data-outputId="50dacd4f-5abb-45ec-ab7e-5510c0d45ede">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plt.hist(df[<span class="st">&quot;question_length&quot;</span>], bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Question Length Distribution&quot;</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Words&quot;</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Frequency&quot;</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/ba27b0da4017498b351aa6fd363e5b3922445682.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="mFnddiZG5uLn" data-outputId="c2f572f2-765c-4992-cf62-eae365394725">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>plt.hist(df[<span class="st">&quot;answer_length&quot;</span>], bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Answer Length Distribution&quot;</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Words&quot;</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Frequency&quot;</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/f2133b98b3b25ff44fc21948f6302bef397f1898.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="5TvOezF15xPZ" data-outputId="b391313a-33c5-46ff-b32f-72b647efc4cc">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>plt.hist(df[<span class="st">&quot;context_length&quot;</span>], bins<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Context Length Distribution&quot;</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Words in Full Paper&quot;</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Frequency&quot;</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/78ab30ce5d02fd01ac181a793217ecfa348ccf9c.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="BjSpu6ff50X7" data-outputId="1801cf1a-20ce-4885-e0e4-3b14f7b1f4d9">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">&quot;question_length&quot;</span>], df[<span class="st">&quot;answer_length&quot;</span>])</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Question Length&quot;</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Answer Length&quot;</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Question vs Answer Length&quot;</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/051a90ff82e1f659f730670b1dfb49cc6c143584.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:511}"
id="EiL8tsUu53S0" data-outputId="ac5b8b0a-e229-4880-b879-b72387579595">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>all_questions <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(df[<span class="st">&quot;question&quot;</span>])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> all_questions.lower().split()</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>common_words <span class="op">=</span> Counter(words).most_common(<span class="dv">20</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>words, counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>common_words)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>plt.bar(words, counts)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Top 20 Question Words&quot;</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b1b36ccc5a547fa9f89b9eff024eb11/4b129cd1cc6b7c3a50e9e97dbb839d4da15bd996.png" /></p>
</div>
</div>
<div class="cell markdown" id="uDc4sNC9-9DJ">
<p>#Text Chunking</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:145,&quot;referenced_widgets&quot;:[&quot;2dc0b4287e2347d5a72138a37fd6bcc8&quot;,&quot;299fec31b4a94a9288b576fb351982b1&quot;,&quot;8de2261d7b8948ea8c4487ae5e5fe00e&quot;,&quot;767bd75fdc06470ebdeadc66be1ab9d1&quot;,&quot;ee9c3704f9304d92a0f9da2e17ccea22&quot;,&quot;dd7cbaae18f74d0298ee151afbd99855&quot;,&quot;21fe2e8ccff94b239b7707a027afa432&quot;,&quot;3e8254e8ee21457a8c83a0e8df34e9f0&quot;,&quot;f8b353920e1442d6831e36b89fcdec30&quot;,&quot;4792e08422bd4effa55ae2f2a7f5d304&quot;,&quot;99845c97c1634e67abe60f20606d5370&quot;,&quot;f9453a4962124869823887356d77e148&quot;,&quot;8606764b5a7b4cf4b2ceaac8b4fad690&quot;,&quot;2da686eadffd49a49f4ac3b4a5a4f386&quot;,&quot;16cb018221f44b40819c19480a1caa07&quot;,&quot;eb70886ddf4840e8823148cc640e4396&quot;,&quot;81a7f1dce5c54d9b93d9e71dfb7fcd75&quot;,&quot;bec69906b2fa4df4bd9286133b429ab3&quot;,&quot;3f03896f79ac48c5ad6dddb89173e644&quot;,&quot;73a98019d9bc495a88628b575d321055&quot;,&quot;e17816890d784ff89d2f1f2e618ed985&quot;,&quot;96b8bb6c14af4714b3430c9a5904392e&quot;,&quot;154cab2b2daf49dfb3c8e9981792d480&quot;,&quot;da0ed186e6c44cc182f64e59817e8f05&quot;,&quot;1bf16640e4ed4683a0ac9d650f04a856&quot;,&quot;4077f20efd9449989b64eeda1a81ab9e&quot;,&quot;d3e67767fbee4f139f210dbf83291ff0&quot;,&quot;bd72eeae1855430190de0eb79dfb513a&quot;,&quot;50593f3895564ef68f112fc60d7923f9&quot;,&quot;81d68f23aa7644258c1a4b3531691027&quot;,&quot;a1e8f599d3d94a26837b4b4cd0450b64&quot;,&quot;7978a438270843638276635be494fd1f&quot;,&quot;eee5f2d82cea462599f67246c41a24c4&quot;,&quot;dbfaa739c4984a8091ee3bb33894338a&quot;,&quot;5e0191606b2a42158586b8d80a02765d&quot;,&quot;69fbf7675faa4a008ee094005e200152&quot;,&quot;b56621e055a74d4b84d25037c6e18395&quot;,&quot;84b0b6c7123040b2a34ee9b2ff45df81&quot;,&quot;9638ab1c8d8740c69a4f925174fc8e44&quot;,&quot;ca7199d9feb44376ac4ad7195a8d01cd&quot;,&quot;24e53b3d3d594458949a3f4f23b6d041&quot;,&quot;8df696ea4f5c4ab19a328084b16f1834&quot;,&quot;bcca63fa008c4e1e9efa0eac3197c769&quot;,&quot;43b3df74864e4c96a55f3efefd158ff0&quot;]}"
id="LqtUVw7W_B5n" data-outputId="e91610ca-6bf0-4771-c398-7213fb505331">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chunk_text(text, chunk_size<span class="op">=</span><span class="dv">300</span>, overlap<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> text.split()</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    chunks <span class="op">=</span> []</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> start <span class="op">&lt;</span> <span class="bu">len</span>(words):</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> words[start : start <span class="op">+</span> chunk_size]</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        chunks.append(<span class="st">&quot; &quot;</span>.join(chunk))</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        start <span class="op">+=</span> chunk_size <span class="op">-</span> overlap</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chunks</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb33"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2dc0b4287e2347d5a72138a37fd6bcc8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb34"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f9453a4962124869823887356d77e148&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb35"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;154cab2b2daf49dfb3c8e9981792d480&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb36"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;dbfaa739c4984a8091ee3bb33894338a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell markdown" id="KlRver2P_Lgb">
<p>#Apply Chunking on Context</p>
</div>
<div class="cell code" id="L1msatyx_Qb_">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>all_chunks <span class="op">=</span> []</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>metadata <span class="op">=</span> []</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract and join the text from &#39;paragraphs&#39; list within the &#39;context&#39; dictionary</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    full_text_content <span class="op">=</span> <span class="st">&#39; &#39;</span>.join([<span class="st">&#39; &#39;</span>.join(section) <span class="cf">for</span> section <span class="kw">in</span> row[<span class="st">&quot;context&quot;</span>][<span class="st">&#39;paragraphs&#39;</span>]])</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    chunks <span class="op">=</span> chunk_text(full_text_content)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch <span class="kw">in</span> chunks:</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        all_chunks.append(ch)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        metadata.append({</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;paper_id&quot;</span>: row[<span class="st">&quot;paper_id&quot;</span>],</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;question&quot;</span>: row[<span class="st">&quot;question&quot;</span>]</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>        })</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="fzE4UudS_gi5" data-outputId="46737a6f-3ff9-4149-948a-2d60fbcbfe49">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install sentence<span class="op">-</span>transformers faiss<span class="op">-</span>cpu</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)
Collecting faiss-cpu
  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)
Requirement already satisfied: transformers&lt;6.0.0,&gt;=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)
Requirement already satisfied: torch&gt;=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)
Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)
Requirement already satisfied: huggingface-hub&gt;=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)
Requirement already satisfied: typing_extensions&gt;=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)
Requirement already satisfied: numpy&lt;3.0,&gt;=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)
Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (3.20.0)
Requirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (2025.3.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (6.0.3)
Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (2.32.4)
Requirement already satisfied: hf-xet&lt;2.0.0,&gt;=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (1.2.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (75.2.0)
Requirement already satisfied: sympy&gt;=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (1.14.0)
Requirement already satisfied: networkx&gt;=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (3.6.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (3.1.6)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers&lt;6.0.0,&gt;=4.41.0-&gt;sentence-transformers) (2025.11.3)
Requirement already satisfied: tokenizers&lt;=0.23.0,&gt;=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers&lt;6.0.0,&gt;=4.41.0-&gt;sentence-transformers) (0.22.1)
Requirement already satisfied: safetensors&gt;=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers&lt;6.0.0,&gt;=4.41.0-&gt;sentence-transformers) (0.7.0)
Requirement already satisfied: joblib&gt;=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-&gt;sentence-transformers) (1.5.3)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-&gt;sentence-transformers) (3.6.0)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy&gt;=1.13.3-&gt;torch&gt;=1.11.0-&gt;sentence-transformers) (1.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-&gt;torch&gt;=1.11.0-&gt;sentence-transformers) (3.0.3)
Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (3.4.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (3.11)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (2.5.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (2025.11.12)
Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.8/23.8 MB 64.1 MB/s eta 0:00:00
</code></pre>
</div>
</div>
<div class="cell markdown" id="v3lAEO4T_pN9">
<p>#Text Embeddings</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:290,&quot;referenced_widgets&quot;:[&quot;41142c79d59b4026b69019eb4bf4faa8&quot;,&quot;5522229ec2c44475b4a134e1683eec61&quot;,&quot;c71fb16248184d52aaaaaa8553526a44&quot;,&quot;99d68ed134bc4251b3fb216a6df192a1&quot;,&quot;acf016a57a3146aa9b5adab640943a16&quot;,&quot;5573ef0483874872b8f0980a863e0bd7&quot;,&quot;7fea121b1321402faba845fd75a0f588&quot;,&quot;7228e9d01ef441209eeea30cdcf3c81e&quot;,&quot;100d0f0425a24980bda81a8ab17fdce3&quot;,&quot;38f23f93c3ab4d17a0b198c1d3be1e53&quot;,&quot;7524168f186649c8a71432f83ae4025e&quot;,&quot;6d381c8db5a049bcb04272ac78ea91ef&quot;,&quot;9b62bd4e70904f9ab72431d4da134f25&quot;,&quot;2a3dd99fa0c44e9c8789053937ccce6c&quot;,&quot;18bbcb5da50944a5a73b3a038b80b46c&quot;,&quot;b0c7dc6362d14b979e98a08e55ae8ae7&quot;,&quot;4c6c8a22d4e2497aa9f0c44666e9baa8&quot;,&quot;c856f4d261834a2bbb058e815684f714&quot;,&quot;08c13fc05e084f5690f086ba332ab3a5&quot;,&quot;41acbe9a164c467b8d6fa11106643ebf&quot;,&quot;0492fb1a9064486a99631f8a8b0a92b0&quot;,&quot;e588abf8535c40bea88a73b17b395a87&quot;,&quot;8f58a3f72b864b478f692599b3345544&quot;,&quot;8c27e6f9bf1d47a692198eef47c132c2&quot;,&quot;c0ba8d1581f445f89deb1cfe09155181&quot;,&quot;d6440264e931472594aa1fc52ef5ce69&quot;,&quot;0adfebc2a7d745e6b0fafb83c83eba24&quot;,&quot;cfbc565245b24240a8cdef9be7e98eb3&quot;,&quot;451350af25c040ad9b9e4395e98e9106&quot;,&quot;a3173943f0df4544ad3d57fc55cf34be&quot;,&quot;cbd68095bb9e49aebaf0c6599457f4d2&quot;,&quot;1c17e5f64ce44b8bbf2dfe9ae1ece2d9&quot;,&quot;065dd0e833c243c28609173645e0f7f5&quot;,&quot;5a157649a242459aa9af74c837f769ea&quot;,&quot;fa77455d350f4709a2227e109381c448&quot;,&quot;0e263a2df2734e0281bb0024f32f1f39&quot;,&quot;e2d4ff53a5514f4b8f3f7a998be31b03&quot;,&quot;6d407c5b963f4b40a11028bed1bd6abf&quot;,&quot;2d05287086ac46dba968129b69f2c722&quot;,&quot;5591298144de4b31bea5401e47140b86&quot;,&quot;584970a7f044407faf78d0c67c98e3bd&quot;,&quot;a8d8e7d32b4c43f886e166cb2e106d0a&quot;,&quot;838d6b7446c64f5fac81c19bcdea5aa9&quot;,&quot;1088210d2992492782ccfa7154390beb&quot;,&quot;6e6734026363438fa0ae0ea4d3a81d9a&quot;,&quot;0c75d46cd4ae43f5a0f1e5632c7ac697&quot;,&quot;4f8129e77de048ac81a48cbf16f49670&quot;,&quot;10cfebbf994349ba8b0e5e3085856444&quot;,&quot;86d58857240543a78ff79d9c63b3d849&quot;,&quot;0c2880efea584db59c1a7663bc77cab5&quot;,&quot;42fe702d83744f25be54d0feb8d51119&quot;,&quot;32ad2810452f4e02a72d370929286bc9&quot;,&quot;fce11bb1d9be410f97a986e29b415587&quot;,&quot;0bf774d782ae40878cb3085eba1ef17c&quot;,&quot;eda0631b14214c9cbf7a045b6fc90da8&quot;,&quot;1f1fb534e1b0495dbe9e85dff4b8a8af&quot;,&quot;353067b4ab3f44d89e28dbe0fc513d7e&quot;,&quot;5d3f4da7776749df99df34ff67c632f3&quot;,&quot;a5091f7d14eb460498d78a824073c93a&quot;,&quot;867fc483c6b6410496192e22cc3d1e4c&quot;,&quot;d9d20cce14414d7884215236e5700b7a&quot;,&quot;a988cf37c1ad4d4083aa9f65122b1404&quot;,&quot;bfb187467d68463ebf646fbee168e03f&quot;,&quot;b22e7744815a4919bbb28fe1a6ddc34c&quot;,&quot;f1e50ece5ee2459c92146d147e8df8b6&quot;,&quot;bb3ea303ff354f35a9490d88a6cb93b2&quot;,&quot;771575b908d942d1a85f5aaf1d8225a8&quot;,&quot;39ca016121b04783a24c0addab55c503&quot;,&quot;eb5852cd40894522bf3144786a15e2a5&quot;,&quot;8efed17e3bc345aaa865f46727756684&quot;,&quot;0f977991d1334748b2d240f56379823a&quot;,&quot;9bc72763af0843b5b35916b09e6b6fa8&quot;,&quot;3f8472e47174402dbe783d9c169073ca&quot;,&quot;3cfab5c207c14866bb2121d0674f9bb0&quot;,&quot;89b9e0a9834a42718d39aea4920e9a67&quot;,&quot;dee2aaa4dfb9491791a2f3892c3e6301&quot;,&quot;98cd71b261cc48e68dbcd77f1eb87fc0&quot;,&quot;0cc24728deaa448cacaf5eee090bb4bd&quot;,&quot;71099390dcc140d899c6111a90008f25&quot;,&quot;73cd04bbaca7429a9f6f45720e804184&quot;,&quot;5655d5ef3a504ae1b71702a2c9349586&quot;,&quot;536d494c38914d1cad4ae014fe938553&quot;,&quot;b815883f3abd4da294becf580b6751e6&quot;,&quot;8900d9e9ace4430f8e06f710a7e84496&quot;,&quot;d0df6a7b8d0141f4979cf1627de55290&quot;,&quot;fe45e223a9c346ef89b29d76d2edfb80&quot;,&quot;ca2ac4e6ce344422814e529689cda48f&quot;,&quot;927511602fe24294970fe4a99286977d&quot;]}"
id="6Vz_7ULf_vVw" data-outputId="b2dfdffb-bf66-47d4-fba6-4e13f07b2faf">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>embed_model <span class="op">=</span> SentenceTransformer(<span class="st">&quot;all-mpnet-base-v2&quot;</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> embed_model.encode(</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    all_chunks,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    show_progress_bar<span class="op">=</span><span class="va">True</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb42"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;41142c79d59b4026b69019eb4bf4faa8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb43"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6d381c8db5a049bcb04272ac78ea91ef&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb44"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8f58a3f72b864b478f692599b3345544&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb45"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5a157649a242459aa9af74c837f769ea&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb46"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6e6734026363438fa0ae0ea4d3a81d9a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb47"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1f1fb534e1b0495dbe9e85dff4b8a8af&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb48"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;771575b908d942d1a85f5aaf1d8225a8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb49"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;0cc24728deaa448cacaf5eee090bb4bd&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Cvz_7qiN-E3w" data-outputId="65628226-9632-43c3-a879-844a839d36a4">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> faiss</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>dimension <span class="op">=</span> embeddings.shape[<span class="dv">1</span>]</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> faiss.IndexFlatL2(dimension)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>index.add(np.array(embeddings))</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Total vectors:&quot;</span>, index.ntotal)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total vectors: 9168
</code></pre>
</div>
</div>
<div class="cell code" id="3g0RpXkJ-ev0">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>faiss.write_index(index, <span class="st">&quot;qasper_faiss.index&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" id="fg5gI78H-mRQ">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> retrieve_chunks(query, k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    q_emb <span class="op">=</span> embed_model.encode([query])</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    D, I <span class="op">=</span> index.search(np.array(q_emb), k)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [all_chunks[i] <span class="cf">for</span> i <span class="kw">in</span> I[<span class="dv">0</span>]]</span></code></pre></div>
</div>
<div class="cell code" id="UpznlVi8-qiu">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_prompt(question, contexts):</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    context_text <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\n\n</span><span class="st">&quot;</span>.join(contexts)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f&quot;&quot;&quot;</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="ss">You are an AI assistant answering questions from research papers.</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="ss">Context:</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>context_text<span class="sc">}</span></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="ss">Question:</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>question<span class="sc">}</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="ss">Answer clearly and concisely.</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a><span class="ss">&quot;&quot;&quot;</span></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> prompt</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:296,&quot;referenced_widgets&quot;:[&quot;b5423482b17248348372d3ce36a1906b&quot;,&quot;97d8bf882ffe4f58a41c70722e8ead83&quot;,&quot;a614ff353e5141a6b92e30835f761003&quot;,&quot;1281e5ffeb42478784a671f56e03aa3d&quot;,&quot;4da84f24e1d846f481fa9e7851e514a6&quot;,&quot;02abbfd4d5164298a1fc7543cd8de89c&quot;,&quot;e1f2c13c8deb430d86b4a317759cf51c&quot;,&quot;ec8f1463049d4cb6bb23b807c4c13145&quot;,&quot;77ac5d06df7d43f5994d9854b80691ce&quot;,&quot;3e9276904cae49db8f09a58e00178525&quot;,&quot;7749afcc2ee14977b11e74c0d78dec2f&quot;,&quot;19e896202b274646b15038c0f4fdbc7f&quot;,&quot;51e8d3385e614b5c962f62e1dd1cdc91&quot;,&quot;75494ec0723247a4b4a6e75b7a67ffbe&quot;,&quot;8c3f5b46559444e19361e012ca246119&quot;,&quot;225ed347d8384a87899f1ab2b21b874f&quot;,&quot;d0c0c61862144ea180932e95cea0730e&quot;,&quot;9ba53a35fb5040fda80753bbe81fdfc4&quot;,&quot;c415e0692cb64432b1153aa88464cf80&quot;,&quot;e144333d98be4aff9f2487c2f9174c9c&quot;,&quot;6897098b6b32480d88ff8a64404338ee&quot;,&quot;f8dcc5f883e9444fa2de553a795e1b4b&quot;,&quot;b708b89036464d9db15579df54950076&quot;,&quot;76992a7ed3ea4a1aba328aa7c9dbdd2d&quot;,&quot;334b9ab06bce44e3b00e7f53cef2dc1d&quot;,&quot;baf990d237594b4c9a34d870dd200c18&quot;,&quot;ab70e01cba4047faaca046219c6cc09f&quot;,&quot;65795bcaaa844476b7bacfeb59e6fd66&quot;,&quot;f2a170b9c3a747a0a11eccee5773678d&quot;,&quot;6048e070590040ba889f6d8bd306eae6&quot;,&quot;626f6c87ad3945aeb099296b49d3b2cd&quot;,&quot;0b96634d9f23403cb6712347b2c70863&quot;,&quot;d24a18b863894053a702e69c055593c0&quot;,&quot;367b8b851a244f3bad4c166db026615d&quot;,&quot;07380e11a99e4547b7f809541138f11b&quot;,&quot;a8e32efb555d443fba68004cf246ef72&quot;,&quot;54e002d42cc54c15adcd7d121ef3e666&quot;,&quot;687a2dada368414bb24baaa33276df96&quot;,&quot;2d63bb9ef0d54637ac0bb75d35ba26cf&quot;,&quot;d09736cb8abd4ed8b8f2e77a98f75107&quot;,&quot;a1ca407b8e4140bd81bf53a02d820c1e&quot;,&quot;d3a5ae37289e4483b88a7b0f46bb43a3&quot;,&quot;e93093616ca145978f3fb43cb633c100&quot;,&quot;76d996fda11d46bb9d400542642f2282&quot;,&quot;c8da395664c14108bde5b5bb29231134&quot;,&quot;a30721050cbb4e489df3089656d30757&quot;,&quot;6d69b6a461ca4228afaec8123efa32da&quot;,&quot;41938847cf754f85bf971b4914955eb4&quot;,&quot;68e3c563e65a4a0f8d28ef7abf941946&quot;,&quot;ccd99be66264458bb86d88eaa971de94&quot;,&quot;446e305ffee64f87b75c4ce0d93986b8&quot;,&quot;b0d2595029de4c3a9c1e219838b618bc&quot;,&quot;19d49002126a4907a58cfbfffeeddeb1&quot;,&quot;d7990d2bd3fa4ff4bc78307b72fa8a06&quot;,&quot;f441bf04646a4079bc4e945d19ef1634&quot;,&quot;1c5cf6446a1a49cda842745f9aa45c22&quot;,&quot;695e339b9f1f41cf8a11abe39965e7d4&quot;,&quot;23ef4dbaefc748199de3e112a4d44e41&quot;,&quot;4c0cda9037c44847afda55586172efb4&quot;,&quot;a882e7462b16451c91bbd32068bd105a&quot;,&quot;55309932718245ad842d294c7a8d8844&quot;,&quot;4121b4f7724a4c14bcd31be3f237f0e9&quot;,&quot;c0716805c8f44749910098b307431bdd&quot;,&quot;b24198c480e84bb1a40e34fd4b2c880d&quot;,&quot;96487a8081604fbb97932d34377a8d7d&quot;,&quot;f6503702a7c64df58b20547725ed1a40&quot;,&quot;03bbb2d4568f42f294ed97e0a1711172&quot;,&quot;9c59a24f33c54de386cd7377ac840906&quot;,&quot;4ea9bb83830e45b7b8a73f5364101e2e&quot;,&quot;f7679e7b334444fca300a8f6984aeea5&quot;,&quot;0e24e39d8d274cb3bfd0e0ad7755d7be&quot;,&quot;9f15c6c77f5f448983af422508e5010c&quot;,&quot;794d7a02f24d4502b74a7edf99e0657f&quot;,&quot;3c82b7b804d54b1b81c6139c9db2e6cd&quot;,&quot;7a5ff0d381fb42bf8c723a94ab11a088&quot;,&quot;9dbec041055e4ada97f65a22225676c8&quot;,&quot;0e21639763a24090ab474170caaf0ad8&quot;]}"
id="oXN9E9WE-tys" data-outputId="f5db1b75-c5a2-4d3e-d0f0-5acfb57976f7">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> pipeline(</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;text-generation&quot;</span>,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;google/flan-t5-base&quot;</span>,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">200</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rag_answer(question):</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    contexts <span class="op">=</span> retrieve_chunks(question)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> build_prompt(question, contexts)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> llm(prompt)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result[<span class="dv">0</span>][<span class="st">&quot;generated_text&quot;</span>]</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb56"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b5423482b17248348372d3ce36a1906b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb57"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;19e896202b274646b15038c0f4fdbc7f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b708b89036464d9db15579df54950076&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;367b8b851a244f3bad4c166db026615d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c8da395664c14108bde5b5bb29231134&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1c5cf6446a1a49cda842745f9aa45c22&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb62"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;03bbb2d4568f42f294ed97e0a1711172&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Device set to use cpu
The model &#39;T5ForConditionalGeneration&#39; is not supported for text-generation. Supported models are [&#39;PeftModelForCausalLM&#39;, &#39;ApertusForCausalLM&#39;, &#39;ArceeForCausalLM&#39;, &#39;AriaTextForCausalLM&#39;, &#39;BambaForCausalLM&#39;, &#39;BartForCausalLM&#39;, &#39;BertLMHeadModel&#39;, &#39;BertGenerationDecoder&#39;, &#39;BigBirdForCausalLM&#39;, &#39;BigBirdPegasusForCausalLM&#39;, &#39;BioGptForCausalLM&#39;, &#39;BitNetForCausalLM&#39;, &#39;BlenderbotForCausalLM&#39;, &#39;BlenderbotSmallForCausalLM&#39;, &#39;BloomForCausalLM&#39;, &#39;BltForCausalLM&#39;, &#39;CamembertForCausalLM&#39;, &#39;LlamaForCausalLM&#39;, &#39;CodeGenForCausalLM&#39;, &#39;CohereForCausalLM&#39;, &#39;Cohere2ForCausalLM&#39;, &#39;CpmAntForCausalLM&#39;, &#39;CTRLLMHeadModel&#39;, &#39;Data2VecTextForCausalLM&#39;, &#39;DbrxForCausalLM&#39;, &#39;DeepseekV2ForCausalLM&#39;, &#39;DeepseekV3ForCausalLM&#39;, &#39;DiffLlamaForCausalLM&#39;, &#39;DogeForCausalLM&#39;, &#39;Dots1ForCausalLM&#39;, &#39;ElectraForCausalLM&#39;, &#39;Emu3ForCausalLM&#39;, &#39;ErnieForCausalLM&#39;, &#39;Ernie4_5ForCausalLM&#39;, &#39;Ernie4_5_MoeForCausalLM&#39;, &#39;Exaone4ForCausalLM&#39;, &#39;FalconForCausalLM&#39;, &#39;FalconH1ForCausalLM&#39;, &#39;FalconMambaForCausalLM&#39;, &#39;FlexOlmoForCausalLM&#39;, &#39;FuyuForCausalLM&#39;, &#39;GemmaForCausalLM&#39;, &#39;Gemma2ForCausalLM&#39;, &#39;Gemma3ForConditionalGeneration&#39;, &#39;Gemma3ForCausalLM&#39;, &#39;Gemma3nForConditionalGeneration&#39;, &#39;Gemma3nForCausalLM&#39;, &#39;GitForCausalLM&#39;, &#39;GlmForCausalLM&#39;, &#39;Glm4ForCausalLM&#39;, &#39;Glm4MoeForCausalLM&#39;, &#39;GotOcr2ForConditionalGeneration&#39;, &#39;GPT2LMHeadModel&#39;, &#39;GPT2LMHeadModel&#39;, &#39;GPTBigCodeForCausalLM&#39;, &#39;GPTNeoForCausalLM&#39;, &#39;GPTNeoXForCausalLM&#39;, &#39;GPTNeoXJapaneseForCausalLM&#39;, &#39;GptOssForCausalLM&#39;, &#39;GPTJForCausalLM&#39;, &#39;GraniteForCausalLM&#39;, &#39;GraniteMoeForCausalLM&#39;, &#39;GraniteMoeHybridForCausalLM&#39;, &#39;GraniteMoeSharedForCausalLM&#39;, &#39;HeliumForCausalLM&#39;, &#39;HunYuanDenseV1ForCausalLM&#39;, &#39;HunYuanMoEV1ForCausalLM&#39;, &#39;JambaForCausalLM&#39;, &#39;JetMoeForCausalLM&#39;, &#39;Lfm2ForCausalLM&#39;, &#39;LlamaForCausalLM&#39;, &#39;Llama4ForCausalLM&#39;, &#39;Llama4ForCausalLM&#39;, &#39;LongcatFlashForCausalLM&#39;, &#39;MambaForCausalLM&#39;, &#39;Mamba2ForCausalLM&#39;, &#39;MarianForCausalLM&#39;, &#39;MBartForCausalLM&#39;, &#39;MegaForCausalLM&#39;, &#39;MegatronBertForCausalLM&#39;, &#39;MiniMaxForCausalLM&#39;, &#39;MinistralForCausalLM&#39;, &#39;MistralForCausalLM&#39;, &#39;MixtralForCausalLM&#39;, &#39;MllamaForCausalLM&#39;, &#39;ModernBertDecoderForCausalLM&#39;, &#39;MoshiForCausalLM&#39;, &#39;MptForCausalLM&#39;, &#39;MusicgenForCausalLM&#39;, &#39;MusicgenMelodyForCausalLM&#39;, &#39;MvpForCausalLM&#39;, &#39;NemotronForCausalLM&#39;, &#39;OlmoForCausalLM&#39;, &#39;Olmo2ForCausalLM&#39;, &#39;Olmo3ForCausalLM&#39;, &#39;OlmoeForCausalLM&#39;, &#39;OpenLlamaForCausalLM&#39;, &#39;OpenAIGPTLMHeadModel&#39;, &#39;OPTForCausalLM&#39;, &#39;PegasusForCausalLM&#39;, &#39;PersimmonForCausalLM&#39;, &#39;PhiForCausalLM&#39;, &#39;Phi3ForCausalLM&#39;, &#39;Phi4MultimodalForCausalLM&#39;, &#39;PhimoeForCausalLM&#39;, &#39;PLBartForCausalLM&#39;, &#39;ProphetNetForCausalLM&#39;, &#39;QDQBertLMHeadModel&#39;, &#39;Qwen2ForCausalLM&#39;, &#39;Qwen2MoeForCausalLM&#39;, &#39;Qwen3ForCausalLM&#39;, &#39;Qwen3MoeForCausalLM&#39;, &#39;Qwen3NextForCausalLM&#39;, &#39;RecurrentGemmaForCausalLM&#39;, &#39;ReformerModelWithLMHead&#39;, &#39;RemBertForCausalLM&#39;, &#39;RobertaForCausalLM&#39;, &#39;RobertaPreLayerNormForCausalLM&#39;, &#39;RoCBertForCausalLM&#39;, &#39;RoFormerForCausalLM&#39;, &#39;RwkvForCausalLM&#39;, &#39;SeedOssForCausalLM&#39;, &#39;SmolLM3ForCausalLM&#39;, &#39;Speech2Text2ForCausalLM&#39;, &#39;StableLmForCausalLM&#39;, &#39;Starcoder2ForCausalLM&#39;, &#39;TransfoXLLMHeadModel&#39;, &#39;TrOCRForCausalLM&#39;, &#39;VaultGemmaForCausalLM&#39;, &#39;WhisperForCausalLM&#39;, &#39;XGLMForCausalLM&#39;, &#39;XLMWithLMHeadModel&#39;, &#39;XLMProphetNetForCausalLM&#39;, &#39;XLMRobertaForCausalLM&#39;, &#39;XLMRobertaXLForCausalLM&#39;, &#39;XLNetLMHeadModel&#39;, &#39;xLSTMForCausalLM&#39;, &#39;XmodForCausalLM&#39;, &#39;ZambaForCausalLM&#39;, &#39;Zamba2ForCausalLM&#39;].
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:160}"
id="27l3PGF--yqA" data-outputId="8580a6d6-9e6b-441f-b8a3-5bf97d83bc19">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>rag_answer(<span class="st">&quot;What is the main contribution of the paper?&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>Token indices sequence length is longer than the specified maximum sequence length for this model (1958 &gt; 512). Running this sequence through the model will result in indexing errors
</code></pre>
</div>
<div class="output execute_result" data-execution_count="28">
<div class="sourceCode" id="cb66"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code" id="KzdKEeFc-36Y">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_qa(row):</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;input_text&quot;</span>: <span class="ss">f&quot;question: </span><span class="sc">{</span>row[<span class="st">&#39;question&#39;</span>]<span class="sc">}</span><span class="ss"> context: </span><span class="sc">{</span>row[<span class="st">&#39;context&#39;</span>]<span class="sc">}</span><span class="ss">&quot;</span>,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;target_text&quot;</span>: row[<span class="st">&quot;answer&quot;</span>]</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the actual number of samples to take</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> <span class="bu">min</span>(<span class="dv">3000</span>, <span class="bu">len</span>(df))</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample the DataFrame</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> df.sample(n<span class="op">=</span>num_samples, random_state<span class="op">=</span><span class="dv">42</span>).<span class="bu">apply</span>(format_qa, axis<span class="op">=</span><span class="dv">1</span>).tolist()</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="kylEGR4K-9zl" data-outputId="0b1fccec-ae67-4734-d462-29bd8da99ff3">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> T5Tokenizer</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> T5Tokenizer.from_pretrained(<span class="st">&quot;google/flan-t5-base&quot;</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(batch):</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">&quot;input_text&quot;</span>],</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> tokenizer(</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">&quot;target_text&quot;</span>],</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">128</span></span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a>    inputs[<span class="st">&quot;labels&quot;</span>] <span class="op">=</span> targets[<span class="st">&quot;input_ids&quot;</span>]</span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> inputs</span></code></pre></div>
<div class="output stream stderr">
<pre><code>You are using the default legacy behaviour of the &lt;class &#39;transformers.models.t5.tokenization_t5.T5Tokenizer&#39;&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
</code></pre>
</div>
</div>
<div class="cell code" id="O04CiB8C_CBd">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> T5ForConditionalGeneration, Trainer, TrainingArguments</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> T5ForConditionalGeneration.from_pretrained(<span class="st">&quot;google/flan-t5-base&quot;</span>)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> TrainingArguments(</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">&quot;./qasper_ft&quot;</span>,</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    save_steps<span class="op">=</span><span class="dv">500</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:715}"
id="ZLMGYKuZCS4N" data-outputId="f27b1615-c777-4a54-c018-1571e4abe0a6">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chatbot(question, history):</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    answer <span class="op">=</span> rag_answer(question)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    history.append((question, answer))</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history, <span class="st">&quot;&quot;</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gr.Blocks(title<span class="op">=</span><span class="st">&quot;Research Paper Q&amp;A Bot&quot;</span>) <span class="im">as</span> demo:</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    gr.Markdown(<span class="st">&quot;&quot;&quot;</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a><span class="st">    # 📄 Research Paper Q&amp;A Bot (QASPER)</span></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="st">    Ask questions about research papers using **LLM + FAISS (RAG pipeline)**.</span></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a><span class="st">    🔹 Powered by QASPER Dataset</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a><span class="st">    🔹 Supports long research papers</span></span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a><span class="st">    🔹 Evidence-based answers</span></span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a><span class="st">    &quot;&quot;&quot;</span>)</span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>    chatbot_ui <span class="op">=</span> gr.Chatbot(</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">&quot;💬 Chat&quot;</span>,</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>        height<span class="op">=</span><span class="dv">400</span></span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gr.Row():</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>        question_box <span class="op">=</span> gr.Textbox(</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>            placeholder<span class="op">=</span><span class="st">&quot;Ask a question about the paper...&quot;</span>,</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="st">&quot;Your Question&quot;</span>,</span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>            lines<span class="op">=</span><span class="dv">2</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gr.Row():</span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>        submit_btn <span class="op">=</span> gr.Button(<span class="st">&quot;🚀 Ask&quot;</span>)</span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>        clear_btn <span class="op">=</span> gr.Button(<span class="st">&quot;🧹 Clear&quot;</span>)</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a>    gr.Markdown(<span class="st">&quot;&quot;&quot;</span></span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a><span class="st">    ### 🧪 Example Questions</span></span>
<span id="cb71-37"><a href="#cb71-37" aria-hidden="true" tabindex="-1"></a><span class="st">    - What is the main contribution of the paper?</span></span>
<span id="cb71-38"><a href="#cb71-38" aria-hidden="true" tabindex="-1"></a><span class="st">    - What dataset is used in the experiments?</span></span>
<span id="cb71-39"><a href="#cb71-39" aria-hidden="true" tabindex="-1"></a><span class="st">    - What evaluation metrics are used?</span></span>
<span id="cb71-40"><a href="#cb71-40" aria-hidden="true" tabindex="-1"></a><span class="st">    - Does the paper compare with previous methods?</span></span>
<span id="cb71-41"><a href="#cb71-41" aria-hidden="true" tabindex="-1"></a><span class="st">    &quot;&quot;&quot;</span>)</span>
<span id="cb71-42"><a href="#cb71-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-43"><a href="#cb71-43" aria-hidden="true" tabindex="-1"></a>    submit_btn.click(</span>
<span id="cb71-44"><a href="#cb71-44" aria-hidden="true" tabindex="-1"></a>        fn<span class="op">=</span>chatbot,</span>
<span id="cb71-45"><a href="#cb71-45" aria-hidden="true" tabindex="-1"></a>        inputs<span class="op">=</span>[question_box, chatbot_ui],</span>
<span id="cb71-46"><a href="#cb71-46" aria-hidden="true" tabindex="-1"></a>        outputs<span class="op">=</span>[chatbot_ui, question_box]</span>
<span id="cb71-47"><a href="#cb71-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb71-48"><a href="#cb71-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-49"><a href="#cb71-49" aria-hidden="true" tabindex="-1"></a>    question_box.submit(</span>
<span id="cb71-50"><a href="#cb71-50" aria-hidden="true" tabindex="-1"></a>        fn<span class="op">=</span>chatbot,</span>
<span id="cb71-51"><a href="#cb71-51" aria-hidden="true" tabindex="-1"></a>        inputs<span class="op">=</span>[question_box, chatbot_ui],</span>
<span id="cb71-52"><a href="#cb71-52" aria-hidden="true" tabindex="-1"></a>        outputs<span class="op">=</span>[chatbot_ui, question_box]</span>
<span id="cb71-53"><a href="#cb71-53" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb71-54"><a href="#cb71-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-55"><a href="#cb71-55" aria-hidden="true" tabindex="-1"></a>    clear_btn.click(</span>
<span id="cb71-56"><a href="#cb71-56" aria-hidden="true" tabindex="-1"></a>        fn<span class="op">=</span><span class="kw">lambda</span>: [],</span>
<span id="cb71-57"><a href="#cb71-57" aria-hidden="true" tabindex="-1"></a>        outputs<span class="op">=</span>chatbot_ui</span>
<span id="cb71-58"><a href="#cb71-58" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb71-59"><a href="#cb71-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-60"><a href="#cb71-60" aria-hidden="true" tabindex="-1"></a>demo.launch()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/tmp/ipython-input-2073859741.py:19: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the &#39;tuples&#39; format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type=&#39;messages&#39; instead, which uses openai-style dictionaries with &#39;role&#39; and &#39;content&#39; keys.
  chatbot_ui = gr.Chatbot(
/tmp/ipython-input-2073859741.py:19: DeprecationWarning: The default value of &#39;allow_tags&#39; in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.
  chatbot_ui = gr.Chatbot(
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

Colab notebook detected. To show errors in colab notebook, set debug=True in launch()
* Running on public URL: https://76eb91cfceee1bb925.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
</code></pre>
</div>
<div class="output display_data">
<div><iframe src="https://76eb91cfceee1bb925.gradio.live" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen></iframe></div>
</div>
<div class="output execute_result" data-execution_count="34">
<pre><code></code></pre>
</div>
</div>
</body>
</html>
